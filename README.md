# AttentionIsAllYouNeed
Recreating from scratch the original encoder-decoder transformers architecture
